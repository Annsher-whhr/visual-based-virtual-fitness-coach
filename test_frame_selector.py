# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ™ºèƒ½å…³é”®å¸§é€‰æ‹©å™¨
æ¼”ç¤ºå¦‚ä½•ä»è§†é¢‘ä¸­é€‰æ‹©ä¸æ ‡å‡†è®­ç»ƒå¸§æœ€åŒ¹é…çš„4å¸§
"""

import cv2
import argparse
from frame_selector import select_frames_by_similarity, visualize_similarity_heatmap
from src.pose_estimation_v2 import estimate_pose
from src.action_recognition import recognize_action
from src.detection import detect_human


def extract_metrics_from_video(video_path):
    """ä»è§†é¢‘ä¸­æå–æ‰€æœ‰å¸§çš„metrics"""
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
    
    metrics_list = []
    frame_count = 0
    
    print(f"æ­£åœ¨åˆ†æè§†é¢‘: {video_path}")
    print("æå–å…³é”®ç‚¹ç‰¹å¾...")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ£€æµ‹äººä½“
        frame_with_detection = detect_human(frame)
        # å§¿æ€ä¼°è®¡
        _, results = estimate_pose(frame_with_detection)
        # åŠ¨ä½œè¯†åˆ«ï¼ˆæå–metricsï¼‰
        metrics = recognize_action(results)
        
        if isinstance(metrics, dict) and metrics:
            metrics_list.append(metrics)
        else:
            # ä¿æŒç´¢å¼•è¿ç»­æ€§ï¼Œæ·»åŠ ç©ºå­—å…¸
            metrics_list.append({})
        
        frame_count += 1
        if frame_count % 10 == 0:
            print(f"  å·²å¤„ç† {frame_count} å¸§...", end='\r')
    
    cap.release()
    print(f"\nâœ… å®Œæˆï¼å…±æå– {len(metrics_list)} å¸§ç‰¹å¾\n")
    
    return metrics_list


def main():
    parser = argparse.ArgumentParser(description='æµ‹è¯•æ™ºèƒ½å…³é”®å¸§é€‰æ‹©å™¨')
    parser.add_argument('-v', '--video', required=True, help='è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--min-gap', type=int, default=3, help='ç›¸é‚»å…³é”®å¸§çš„æœ€å°é—´éš”')
    parser.add_argument('--no-viz', action='store_true', help='ä¸ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨')
    args = parser.parse_args()
    
    # 1. ä»è§†é¢‘æå–metrics
    metrics_list = extract_metrics_from_video(args.video)
    
    if len(metrics_list) < 4:
        print(f"âŒ é”™è¯¯ï¼šè§†é¢‘å¸§æ•°ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘4å¸§ï¼Œå®é™…{len(metrics_list)}å¸§ï¼‰")
        return
    
    valid_count = sum(1 for m in metrics_list if isinstance(m, dict) and m)
    print(f"æœ‰æ•ˆç‰¹å¾å¸§æ•°: {valid_count}/{len(metrics_list)}")
    
    if valid_count < 4:
        print("âŒ é”™è¯¯ï¼šæœ‰æ•ˆå¸§æ•°ä¸è¶³4å¸§ï¼Œè¯·æ£€æŸ¥è§†é¢‘ä¸­çš„äººä½“æ£€æµ‹è´¨é‡")
        return
    
    # 2. æ™ºèƒ½é€‰å¸§
    print("\n" + "="*60)
    print("å¼€å§‹æ™ºèƒ½é€‰å¸§...")
    print("="*60)
    
    try:
        indices, info = select_frames_by_similarity(
            metrics_list,
            min_frame_gap=args.min_gap,
            verbose=True
        )
        
        # 3. å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
        if not args.no_viz:
            visualize_similarity_heatmap(info['similarity_matrix'], indices)
        
        # 4. æ˜¾ç¤ºé€‰ä¸­å¸§çš„è¯¦ç»†ç‰¹å¾å¯¹æ¯”
        print("\n" + "="*60)
        print("é€‰ä¸­å¸§çš„ç‰¹å¾è¯¦ç»†å¯¹æ¯”")
        print("="*60)
        
        from frame_selector import STANDARD_FRAMES
        
        for j, idx in enumerate(indices):
            print(f"\nã€æ ‡å‡†å¸§ {j+1} â†â†’ è§†é¢‘å¸§ {idx}ã€‘")
            print(f"  ç›¸ä¼¼åº¦åˆ†æ•°: {info['individual_scores'][j]:.2f}%")
            
            metrics = metrics_list[idx]
            std_frame = STANDARD_FRAMES[j]
            
            # æ˜¾ç¤ºå…³é”®ç‰¹å¾å¯¹æ¯”
            key_features = ['arm_height_ratio', 'foot_distance', 'hand_distance', 
                          'knee_bend_average', 'torso_angle']
            
            if j == 2:  # ç¬¬3å¸§é¢å¤–æ˜¾ç¤ºè‚˜éƒ¨è§’åº¦
                key_features.extend(['left_elbow_angle', 'right_elbow_angle'])
            if j == 3:  # ç¬¬4å¸§é¢å¤–æ˜¾ç¤ºè†ç›–è§’åº¦
                key_features.extend(['left_knee_angle', 'right_knee_angle'])
            
            for feat in key_features:
                val_video = metrics.get(feat, None)
                val_std = std_frame.get(feat, None)
                
                if val_video is not None and val_std is not None:
                    diff = abs(val_video - val_std)
                    diff_pct = (diff / (abs(val_std) + 1e-6)) * 100
                    
                    print(f"  {feat:20s}: è§†é¢‘={val_video:7.3f}  æ ‡å‡†={val_std:7.3f}  "
                          f"å·®å¼‚={diff:6.3f} ({diff_pct:5.1f}%)")
        
        print("\n" + "="*60)
        print(f"âœ… æ™ºèƒ½é€‰å¸§å®Œæˆï¼")
        print(f"   é€‰ä¸­çš„å¸§ç´¢å¼•: {indices}")
        print(f"   å¹³å‡ç›¸ä¼¼åº¦: {info['avg_similarity']:.2f}%")
        print("="*60 + "\n")
        
        # 5. æç¤ºå¯ä»¥ç”¨äºæ¨¡å‹é¢„æµ‹
        print("ğŸ’¡ æç¤ºï¼šè¿™4å¸§ç°åœ¨å¯ä»¥è¾“å…¥åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­è¿›è¡ŒåŠ¨ä½œè´¨é‡è¯„ä¼°")
        print(f"   ä½¿ç”¨å‘½ä»¤: python main.py -v {args.video}")
        
    except Exception as e:
        print(f"\nâŒ é€‰å¸§è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

